{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP final NLP ECI-2019 Jorge Hané's Team.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "AjaibwyFcZvt"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Yerro/NLP-ECI2019/blob/master/TP_final_NLP_ECI_2019_Jorge_Han%C3%A9's_Team.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eczJpJaNqNnn",
        "colab_type": "text"
      },
      "source": [
        "# ECI 2019 - NLP\n",
        "\n",
        "## TP del curso \"Procesamiento del lenguaje natural mediante redes neuronales\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMtlF75QUNh9",
        "colab_type": "text"
      },
      "source": [
        "**Equipo**: Jorge Hané's Team.\n",
        "\n",
        "**Integrantes**:\n",
        "\n",
        "-Juan Musmarra\n",
        "\n",
        "-Nicolás Ojea\n",
        "\n",
        "-Matías Yerro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_lXQ0Z2Toe9",
        "colab_type": "text"
      },
      "source": [
        "**Consigna**:\n",
        "Uno de los datasets más famosos de Natural Language Inference es el SNLI. En esta tarea se debe responder, dadas dos frases A y B, si B es implicación de A (\"entailment\"), B es contradictorio con A (\"contradiction\") o si lo que enuncia B es neutral respecto de A (\"neutral\"). Se dice que A es la premisa y B es la hipótesis.\n",
        "\n",
        "En **Gururangan et al., 2018** mostraron que este dataset tiene algunos sesgos, provocados por ejemplo por las heurísticas que tienen los humanos para generar estos pares de frases (A, B). Para ello, desarrollaron un modelo que aún sin observar la premisa A pudiera clasificar el par (A, B) en alguna de las tres clases del dataset.\n",
        "\n",
        "En este trabajo práctico intentaremos predecir a qué clase pertenece cada una de las hipótesis sin observar la premisa. La idea es replicar los resultados publicados en Gururangan et al., 2018 y mejorarlos si es posible utilizando clasificadores más complejos.\n",
        "\n",
        "Condiciones de entrega\n",
        "Además de realizar al menos un envío replicando los resultados del paper antes mencionados, se deberá entregar el código del trabajo práctico junto a un breve informe que explique la idea del modelo implementado y una indicación de cómo ejecutar el programa si fuera necesaria. Ambos elementos se deben enviar al mail germank+eci2019 (así, con el más eci2019, todo junto) arroba gmail punto com. El trabajo podrá hacerse en grupos de hasta 3 personas. Los integrantes deben estar registrados enviando el siguiente formulario: https://forms.gle/gdqZ4WWcU6xucgqu8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtUlV0r2U-c4",
        "colab_type": "text"
      },
      "source": [
        "**Informe**: \n",
        "\n",
        "El trabajo realizado consta de la aplicación de **fastText** sobre el mismo subconjunto del **SNLI** trabajado por Gururangan et al. (2018). Para mayor comodidad tanto en la realización del TP como así en la entrega del mismo, se utilizó el formato Notebook. Tanto el informe como el código se encuentra en el presente archivo.\n",
        "\n",
        "Se apuntó primero a desarrollar un modelo lo más simple posible, siguiendo la consigna del trabajo, de modo tal que sirviera de \"benchmark\" a modelos más complejos. \n",
        "\n",
        "Los pasos realizados para obtener nuestro mejor resultado fueron los siguientes: \n",
        "\n",
        "    -Carga de archivos a partir del Drive\n",
        "\n",
        "    -Preprocesamiento del texto (pasar todo a minúsculas y eliminar signos de puntuación)\n",
        "    \n",
        "    -Incorporación de dos índices a cada oración: el número total de palabras en dicha oración (dato importante según el paper), y el __label__ que permita aplicar fastText de manera supervisada (excepto al conjunto de Test, claramente).\n",
        "    \n",
        "    -Instalación de fastText y prueba con un modelo por defecto.\n",
        "    \n",
        "    -Batería de modelos en paralelo, para comparar los resultados a partir de la modificación de parámetros.\n",
        "    \n",
        "    -Selección del mejor modelo.\n",
        "    \n",
        "    -Adaptación de los resultados al formato de Kaggle.\n",
        "    \n",
        "Por medio de una parametrización adecuada del fastText hemos logrado 0.68171 en el public leaderboard. El nombre del equipo surgió de la sorpresa de utilizar un código mínimo para obtener lo que a nuestro entender es un resultado aceptable, y de la homofonía del \"reduced fastText\" con cierto producto muy popular en los infomerciales argentinos de hace unos años.\n",
        "\n",
        "Además de los desarrollos presentados en este informe, hemos intentado diferentes modelos que no han producido iguales rendimientos. Primero aplicamos CountVectorizer / TfidfVectorizer a las oraciones y usamos esas sparse matrix para la construcción de diferentes modelos (obviando el uso de herramientas como word2vec o fastText). Entre los modelos trabajados podemos mencionar una regresión logística (arrojó .65 en el dev), y varias FFNN (con múltiples capas, funciones de activación, regularización, algoritmos de optimización, etc.). Debido a la importancia de tiempo de procesamiento para comparar las distintas versiones de redes neuronales, se adaptaron los modelos para ser corridos en TPU. Ninguno de estos modelos obtuvo un rendimiento superior al fastText bien parametrizado.\n",
        "\n",
        "Incluso intentamos utilizar los embeddings producto del fastText como imput para esas FFNN, pero aquí nuevamente ninguna logró superar los valores alcanzados por fastText. Quizás modelos más complejos como LSTM o CNN podrían trabajar con estos embeddings y superar la clasificación mediante fastText sólo, pero nuestros resultados en este sentido con FFNN no han sido superadores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG_ZXP2Z2NIJ",
        "colab_type": "text"
      },
      "source": [
        "## Carga de archivos a partir del Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRVL1pH_zkNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data_folder = 'gdrive/My Drive/NLP/'\n",
        "\n",
        "labels_dev = pd.read_csv(data_folder + 'snli_1.0_dev_gold_labels.csv')\n",
        "labels_train = pd.read_csv(data_folder + 'snli_1.0_train_gold_labels.csv')\n",
        "\n",
        "data_train = pd.read_json(data_folder + 'snli_1.0_train_filtered.jsonl', lines=True)\n",
        "data_dev = pd.read_json(data_folder + 'snli_1.0_dev_filtered.jsonl', lines=True)\n",
        "data_test = pd.read_json(data_folder + 'snli_1.0_test_filtered.jsonl', lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ZiAbmaJ8bz",
        "colab_type": "text"
      },
      "source": [
        "##Preprocesamiento del texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fob4Wme7KDWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train[\"sentence2\"] = data_train[\"sentence2\"].str.lower()\n",
        "data_dev[\"sentence2\"] = data_dev[\"sentence2\"].str.lower()\n",
        "data_test[\"sentence2\"] = data_test[\"sentence2\"].str.lower()\n",
        "\n",
        "import string\n",
        "Tabel = str.maketrans('', '', string.punctuation)\n",
        "data_train[\"sentence2\"] = data_train[\"sentence2\"].str.translate(Tabel)\n",
        "data_dev[\"sentence2\"] = data_dev[\"sentence2\"].str.translate(Tabel)\n",
        "data_test[\"sentence2\"] = data_test[\"sentence2\"].str.translate(Tabel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fise8FOrjPOb",
        "colab_type": "text"
      },
      "source": [
        "## Creación de los dataframes a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVrv7yyMmWEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.concat([data_train['sentence2'], labels_train['gold_label']], axis=1, keys=['sentence', 'label'])\n",
        "df_train['sentence_label'] = df_train.apply(lambda row: '__label__'+row['label']+' '+row['sentence'], axis=1)\n",
        "df_train['n_words'] = df_train['sentence'].str.split().apply(len)\n",
        "# df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT1jVkNxoiOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dev = pd.concat([data_dev['sentence2'], labels_dev['gold_label']], axis=1, keys=['sentence', 'label'])\n",
        "df_dev['sentence_label'] = df_dev.apply(lambda row: '__label__'+row['label']+' '+row['sentence'], axis=1)\n",
        "df_dev['n_words'] = df_dev['sentence'].str.split().apply(len)\n",
        "# df_dev.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRslLqpeoQwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.concat([data_test['sentence2'], data_test['pairID']], axis=1, keys=['sentence', 'pairID'])\n",
        "df_test['n_words'] = df_test['sentence'].str.split().apply(len)\n",
        "# df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bOyArYppfx7",
        "colab_type": "text"
      },
      "source": [
        "# Reduce(d) (Fat) fastText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NskCexF2wY6",
        "colab_type": "text"
      },
      "source": [
        "## Creación de los txt para fastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMISIlxo24C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.savetxt(data_folder+'train.txt', df_train['sentence_label'].values, fmt='%s')\n",
        "np.savetxt(data_folder+'dev.txt', df_dev['sentence_label'].values, fmt='%s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IT7dMnV25Cg",
        "colab_type": "text"
      },
      "source": [
        "## Instalación de fastText. Primer modelo con parámetros por defecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teP0bkACwYMP",
        "colab_type": "code",
        "outputId": "3e2922b5-549b-4f51-e159-304777f33266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "!pip install fasttext\n",
        "import fasttext\n",
        "\n",
        "def print_results(N, p, r):\n",
        "    print(\"N\\t\" + str(N))\n",
        "    print(\"P@{}\\t{:.6f}\".format(1, p))\n",
        "    print(\"R@{}\\t{:.6f}\".format(1, r))\n",
        "\n",
        "jorge_hane = fasttext.train_supervised(data_folder+'train.txt')\n",
        "print_results(*jorge_hane.test(data_folder+'dev.txt'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.16.4)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (41.0.1)\n",
            "N\t9842\n",
            "P@1\t0.645499\n",
            "R@1\t0.645499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S0oddxS5ESY",
        "colab_type": "text"
      },
      "source": [
        "## Batería de prueba de parámetros para mejorar el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncwuJ28YBn0B",
        "colab_type": "text"
      },
      "source": [
        "PARÁMETROS POR DEFECTO ([FUENTE](https://pypi.org/project/fasttext/#train-supervised-parameters))\n",
        "```\n",
        "input             # training file path (required)\n",
        "lr                # learning rate [0.1]\n",
        "dim               # size of word vectors [100]\n",
        "ws                # size of the context window [5]\n",
        "epoch             # number of epochs [5]\n",
        "minCount          # minimal number of word occurences [1]\n",
        "minCountLabel     # minimal number of label occurences [1]\n",
        "minn              # min length of char ngram [0]\n",
        "maxn              # max length of char ngram [0]\n",
        "neg               # number of negatives sampled [5]\n",
        "wordNgrams        # max length of word ngram [1]\n",
        "loss              # loss function {ns, hs, softmax, ova} [softmax]\n",
        "bucket            # number of buckets [2000000]\n",
        "thread            # number of threads [number of cpus]\n",
        "lrUpdateRate      # change the rate of updates for the learning rate [100]\n",
        "t                 # sampling threshold [0.0001]\n",
        "label             # label prefix ['__label__']\n",
        "verbose           # verbose [2]\n",
        "pretrainedVectors # pretrained word vectors (.vec file) for supervised learning []\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2McsbAeOeQGV",
        "colab_type": "code",
        "outputId": "a12ed8b3-5cdf-434b-e161-04e67f076475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "#Esta celda contenía varios fasttext.train_supervised con diferentes parámetros con el objetivo de mejorar el resultado alcanzado con el modelo por defecto.\n",
        "#Se los ha eliminado con el objetivo de mejorar la legibilidad del trabajo."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jorge Hané, First of His Name, King of the Andals and the First Men, Lord of the Six Kingdoms, and Protector of the Realm\n",
            "N\t9842\n",
            "P@1\t0.678013\n",
            "R@1\t0.678013\n",
            "Hané the second\n",
            "N\t9842\n",
            "P@1\t0.675574\n",
            "R@1\t0.675574\n",
            "Hané the third\n",
            "N\t9842\n",
            "P@1\t0.676590\n",
            "R@1\t0.676590\n",
            "Hané Hané Hané Hané\n",
            "N\t9842\n",
            "P@1\t0.676692\n",
            "R@1\t0.676692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XobzI7iJ3N4",
        "colab_type": "text"
      },
      "source": [
        "## El mejor modelo por ahora."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoX6CXaZNDDM",
        "colab_type": "code",
        "outputId": "d2c20bf2-afed-4be2-bbb5-bd5f7cdb751c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "jorge_hane_best = fasttext.train_supervised(data_folder+'train.txt', lr=0.11, dim=170, ws=5, wordNgrams=2, loss='ova', epoch=7)\n",
        "print_results(*jorge_hane_best.test(data_folder+'dev.txt'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N\t9842\n",
            "P@1\t0.681467\n",
            "R@1\t0.681467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxwmwU7RdRkb",
        "colab_type": "text"
      },
      "source": [
        "## Guardo predicciones de jorge_hane_best en un csv para subir a kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Yy7ln5eT6U",
        "colab_type": "code",
        "outputId": "8c6c3dee-e582-4c54-f04d-0ff12fd99a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "def hane_predict(sentence, fasttext_model=jorge_hane_best):\n",
        "  return fasttext_model.predict(sentence)[0][0].replace('__label__', '')\n",
        "\n",
        "df_test['jorge_hane_best_predicted_label'] = df_test['sentence'].apply(hane_predict)\n",
        "\n",
        "df_para_subir_con_jorge_hane_best_predicted_labels = pd.concat([df_test['pairID'], df_test['jorge_hane_best_predicted_label']], axis=1, keys=['pairID', 'gold_label'])\n",
        "print(df_para_subir_con_jorge_hane_best_predicted_labels.head())\n",
        "\n",
        "df_para_subir_con_jorge_hane_best_predicted_labels.to_csv(data_folder+'result.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                pairID     gold_label\n",
            "0  2677109430.jpg#1r1n  contradiction\n",
            "1  2677109430.jpg#1r1e        neutral\n",
            "2  2677109430.jpg#1r1c  contradiction\n",
            "3  6160193920.jpg#4r1n        neutral\n",
            "4  6160193920.jpg#4r1e        neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AjaibwyFcZvt"
      },
      "source": [
        "# Otras locuras..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h9YRbmlqcYJq"
      },
      "source": [
        "## Chequeo si pairID es predictor perfecto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0pZjqjiNb0Cb",
        "colab": {}
      },
      "source": [
        "def check_label_in_last_char_of_pair_id(df=labels_train):\n",
        "  for index, row in df.iterrows():\n",
        "     if row['pairID'][-1] == 'n' and row['gold_label'] != 'neutral' or \\\n",
        "      row['pairID'][-1] == 'e' and row['gold_label'] != 'entailment' or \\\n",
        "      row['pairID'][-1] == 'c' and row['gold_label'] != 'contradiction':\n",
        "        print('El label no coincide con la ultima letra del pairID para el indice: {}'.format(index))\n",
        "        return False\n",
        "  return True\n",
        "print(check_label_in_last_char_of_pair_id())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l29guQTcen5M",
        "colab_type": "text"
      },
      "source": [
        "## Diferencias entre 2 result.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fxu7lWYenBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_res = pd.read_csv(data_folder+'result.csv', index_col=0)\n",
        "df_res_old = pd.read_csv(data_folder+'result_old.csv', index_col=0)\n",
        "df_all = pd.concat([df_res['gold_label'], df_res_old['gold_label']], axis=1, keys=['label_res', 'label_res_old'])\n",
        "df_all.head()\n",
        "df.query('label_res != label_res_old')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}